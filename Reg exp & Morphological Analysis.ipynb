{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re, os, nltk\n",
        "for Folder in ['./Q1_out','./Q2_out2']:\n",
        "  os.makedirs(Folder,exist_ok=True)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQtzx44a3DWb",
        "outputId": "0f22a34e-8d2b-4bbb-a3cd-6db2ba702949"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "def contexts(folder_name, file_name, search_word, min_freq):\n",
        "    with open(f'/content/drive/MyDrive/{file_name}', 'r') as f:\n",
        "        text = f.read()\n",
        "    filenameonly = file_name.split('.')[0]\n",
        "    words = set(nltk.corpus.words.words())\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    filtered_tokens = [token.lower() for token in tokens if token.lower() in words]\n",
        "    occurrences = [index for index, token in enumerate(filtered_tokens) if token == search_word.lower()]\n",
        "    pairs = [(filtered_tokens[max(0, index - 1):min(len(filtered_tokens), index + 2)]) for index in occurrences]\n",
        "    pairs = [(context[0], context[2]) for context in pairs if len(context) == 3 and context[1] == search_word.lower()]\n",
        "    freq_dist = nltk.FreqDist(pairs)\n",
        "    sorted_freq_dist = sorted(freq_dist.items(), key=lambda x: (-x[1], x[0]))\n",
        "    output_file = f'/content/{folder_name}_out/{filenameonly}_context_{search_word.lower()}_{min_freq}.txt'\n",
        "    with open(output_file, 'w') as f:\n",
        "      f.writelines([f'{previous_word}_{after_word}\\t{freq}\\n' for (previous_word, after_word), freq in sorted_freq_dist if freq >= min_freq])\n",
        "\n",
        "contexts('Q1', 'Q1_data01.txt', 'The', 3)\n"
      ],
      "metadata": {
        "id": "rhMeiQIO4GZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7a4dad-253f-4deb-bb79-d6defc0a83d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "import os\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "input_dir, output_dir = \"/content/drive/MyDrive/Q2\", \"/content/Q2_out2\"\n",
        "nltk.download('punkt')\n",
        "for file in os.listdir(input_dir):\n",
        "    with open(os.path.join(input_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
        "        morpheme_analysis = [\n",
        "            (morph, tag)\n",
        "            for sentence in sent_tokenize(f.read())\n",
        "            for token in word_tokenize(sentence)\n",
        "            if (match := re.search(r\"([^/]+)/([A-Z]+)\", token)) is not None\n",
        "            for morph, tag in [match.groups()]\n",
        "        ]\n",
        "    with open(os.path.join(output_dir, file.replace(\".txt\", \"_morph.txt\")), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join([\"/\".join(analysis) for analysis in morpheme_analysis] + [\"\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdpvSEgV3AZc",
        "outputId": "e7cc0374-6da7-4519-f038-b07322009f24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "folder_path = '/content/drive/MyDrive/Q3'\n",
        "\n",
        "frequency_list = [(filename[2], occurrence[0]) for filename in os.listdir(folder_path) if filename.endswith('.txt') for occurrence in re.findall(r'(.{0,10})\\bSP\\b', open(os.path.join(folder_path, filename), 'r').read()) if occurrence]\n",
        "\n",
        "frequency_table = nltk.ConditionalFreqDist(frequency_list)\n",
        "\n",
        "frequency_table.tabulate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA8XlUt2fsKX",
        "outputId": "e32683fd-4432-4f92-c6a1-f02ad353dd48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ,     .     /     :     ;     ·     ，     ：     ； \n",
            "A  6708  3673  2925    91    68  2585     0     0     0 \n",
            "B  4171  1047   367   204     3   610     0     5     0 \n",
            "D  2429    55    10    97     5     0     0     0     0 \n",
            "E  8567    12     5    45     0    56     0     0     0 \n",
            "G  3125     9     0    12     0    90     0     0     0 \n",
            "H 35348  2293   214  1136    94  4514     1     1     4 \n",
            "J   335     1     2     0     0     0     0     0     0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_Orklno2_YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "th7xhAOZgm-a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}